{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the model that will be used to train the deep convolutional neaural network.\n",
    "\n",
    "@Author : Aaron Ward \n",
    "'''\n",
    "import tensorflow as tf\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import skimage\n",
    "from skimage import data, io, filters\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_DIR = '/data/training'\n",
    "MODEL_PATH = '/output/trained_model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "####################################### DATA PREPROCESSING - Labeling ################################################\n",
    "'''\n",
    "This function traverses throwe ach directory of training images\n",
    "Two lists are made:\n",
    "    - The RGB image values are added to the images list\n",
    "    - For every photo in say the 'angry' directory of images, a \n",
    "      corresponding label is added to the label list\n",
    "\n",
    "'''\n",
    "def load_data(TRAINING_DIR):\n",
    "    images = []\n",
    "    labels = []\n",
    "    directories = [d for d in os.listdir(TRAINING_DIR) \n",
    "                if os.path.isdir(os.path.join(TRAINING_DIR, d))]\n",
    "    # Need to sort these because\n",
    "    # floyd hum jumbled up the order\n",
    "    directories = sorted(directories, key=int)\n",
    "\n",
    "    # Traverse through each directory and make a list\n",
    "    # of files names if they end in the PNG format\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(TRAINING_DIR, d)\n",
    "        file_names = [os.path.join(label_directory, f) \n",
    "                        for f in os.listdir(label_directory) \n",
    "                          if f.endswith(\".png\")]\n",
    "        #Traverse through each file, add the image data\n",
    "        # and label to the 2 lists\n",
    "        for f in file_names:\n",
    "            images.append(skimage.data.imread(f))\n",
    "            labels.append(int(d))\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_data(TRAINING_DIR)\n",
    "\n",
    "\n",
    "images = np.array(images, object)\n",
    "labels = np.array(labels, object)\n",
    "\n",
    "# Convert labels into a one hot vector \n",
    "labels = pd.get_dummies(labels)\n",
    "# print(labels[1350:1401])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down scaling images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Downscaled...\n"
     ]
    }
   ],
   "source": [
    "####################################### DATA PREPROCESSING - Imaging #######################################\n",
    "'''\n",
    "This cell is for image downsampling and transformation\n",
    "This is on the fly to resize the images to a 50x50 size\n",
    "'''\n",
    "from skimage import transform, exposure\n",
    "# from skimage.color import rgb2gray\n",
    "\n",
    "print('Down scaling images...')\n",
    "images = [transform.resize(image, (50, 50)) for image in images]\n",
    "\n",
    "# print('equalizing exposure...')\n",
    "# images = [exposure.equalize_adapthist(image, clip_limit=0.0001)for image in images50]\n",
    "\n",
    "print('Images Downscaled...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-ecc5483673f6>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-ecc5483673f6>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    y = tf.placeholder(dtype = tf.int32, shape= [batch_size, num_classes]name=\"Y_placeholder\")\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell is for initializing variables for the tensorflow session and \n",
    "placeholders for holding the data.\n",
    "\n",
    "'''\n",
    "\n",
    "# Define initial variables\n",
    "batch_size = 100\n",
    "num_class = 6\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize placeholders \n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 50, 50], name='X_placeholder')\n",
    "y = tf.placeholder(dtype = tf.int32, shape= [batch_size, num_classes]name=\"Y_placeholder\")\n",
    "\n",
    "\n",
    "#define variables for dropout\n",
    "keep_rate = .8\n",
    "keep_prop = tf.placeholder(tf.float32)\n",
    "print('initialized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpers defined\n"
     ]
    }
   ],
   "source": [
    "######################################### HELPER FUNCTIONS #################################################\n",
    "\n",
    "'''\n",
    "This cell just contains helper functions for defining convolution\n",
    "and maxpooling layers\n",
    "\n",
    "'''\n",
    "\n",
    "# Extract features\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') #move one pixel at s time\n",
    "\n",
    "#\n",
    "def maxpool2d(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #pool 2 pixels at a time\n",
    "\n",
    "print('helpers defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network defined\n"
     ]
    }
   ],
   "source": [
    "########################################## NETWORK DEFINITION ################################################\n",
    "'''\n",
    "This cell contains a function that is used define the weights and biases of each layer in the\n",
    "network. It is called by the train_network function. It also lays out the\n",
    "structure of the network that goes as follows:\n",
    "conv1 -> maxpooling -> conv2 -> maxpooling - > conv3 -> fully connected layer (with dropout) -> output layer\n",
    "\n",
    "'''\n",
    "\n",
    "# Define the weights and biases as dictionaries and\n",
    "# define structure of the network\n",
    "def convolutional_network(x):\n",
    "    weights = {\n",
    "        'weights_conv1' : tf.Variable(tf.random_normal([5,5,1,64])),\n",
    "        'weights_conv2' : tf.Variable(tf.random_normal([5,5,64,128])),\n",
    "        'weights_conv3' : tf.Variable(tf.random_normal([5,5,128,256])),\n",
    "        'weights_fully_con' : tf.Variable(tf.random_normal([7*7*128,4096])),\n",
    "        'weights_out' : tf.Variable(tf.random_normal([4096, num_class]))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'bias_conv1' : tf.Variable(tf.random_normal([64])),\n",
    "        'bias_conv2' : tf.Variable(tf.random_normal([128])),\n",
    "        'bias_conv3' : tf.Variable(tf.random_normal([256])),\n",
    "        'bias_fully_con' : tf.Variable(tf.random_normal([4096])),\n",
    "        'bias_out' : tf.Variable(tf.random_normal([num_class])) #CHANGE THIS IF NO USE\n",
    "    }\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, 50, 50, 1])\n",
    "\n",
    "    # 3 convolutional and 3 max pooling layers\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['weights_conv1']) + biases['bias_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['weights_conv2']) + biases['bias_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    conv3 = tf.nn.relu(conv2d(conv2, weights['weights_conv3']) + biases['bias_conv3'])\n",
    "    conv3 = maxpool2d(conv3)\n",
    "\n",
    "    # The fully connected layer\n",
    "    fully_con = tf.reshape(conv3, [-1, 7*7*128])\n",
    "    fully_con = tf.nn.relu(tf.matmul(fully_con, weights['weights_fully_con']) + biases['bias_fully_con'])\n",
    "    \n",
    "    #Apply dropout - 80% of the neurons are kept\n",
    "    fully_con = tf.nn.dropout(fully_con, keep_rate) # Apply dropout\n",
    "\n",
    "    output = tf.matmul(fully_con, weights['weights_out']) + biases['bias_out']\n",
    "    return output\n",
    "\n",
    "print('network defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400  images\n",
      "8400  labels\n",
      "batch size  100\n",
      "Number of batches  84\n"
     ]
    }
   ],
   "source": [
    "######################################## TENSORFLOW SESSION ###################################################\n",
    "'''\n",
    "This cell is for segmenting the training data in to batches to relieve the GPU of being overloaded\n",
    "with data.\n",
    "EACH BATCH: 100 values (images data or label)\n",
    "EACH CLASS: 14 batch\n",
    "TOTAL BATCHES: 84 (14 x 6 classes = 84)\n",
    "\n",
    "FOR EXAMPLE\n",
    "BATCH_LABELS = [[0,0,0,0,0 ... 0], [0,0,0,0 .... 0]  ... 14 batches per class ... [1,1,1,1,1 .. 1], [1,1,1,1 ..] ...[...,5,5]] \n",
    "\n",
    "'''\n",
    "# 8400 images and 8400 labels\n",
    "num_images = len(images)\n",
    "num_labels = len(labels)\n",
    "\n",
    "# ## KEEP THESE FOR DEBUGGING\n",
    "print(num_images, ' images')\n",
    "print(num_labels, ' labels')\n",
    "print('batch size ', batch_size)\n",
    "print('Number of batches ', int(num_images/batch_size))\n",
    "\n",
    "batch_start= 0\n",
    "batch_end = 100\n",
    "\n",
    "BATCHES_IMAGES = []\n",
    "BATCHES_LABELS = []\n",
    "\n",
    "# batch images into 84 batchs of size 100\n",
    "for i in range(int(num_images/batch_size)):\n",
    "    temp_batch = images[batch_start:batch_end]\n",
    "    BATCHES_IMAGES.append(temp_batch)\n",
    "    batch_start = batch_start + 100\n",
    "    batch_end = batch_end + 100\n",
    "\n",
    "batch_start = 0\n",
    "batch_end = 100\n",
    "# batch the 8400 Label into 84 batchs of 100\n",
    "for i in range(int(num_labels/batch_size)):\n",
    "    temp_batch = labels[batch_start:batch_end]\n",
    "    BATCHES_LABELS.append(temp_batch)\n",
    "    batch_start = batch_start + 100\n",
    "    batch_end = batch_end + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1  2  3  4  5\n",
      "1400  0  1  0  0  0  0\n",
      "1401  0  1  0  0  0  0\n",
      "1402  0  1  0  0  0  0\n",
      "1403  0  1  0  0  0  0\n",
      "1404  0  1  0  0  0  0\n",
      "1405  0  1  0  0  0  0\n",
      "1406  0  1  0  0  0  0\n",
      "1407  0  1  0  0  0  0\n",
      "1408  0  1  0  0  0  0\n",
      "1409  0  1  0  0  0  0\n",
      "1410  0  1  0  0  0  0\n",
      "1411  0  1  0  0  0  0\n",
      "1412  0  1  0  0  0  0\n",
      "1413  0  1  0  0  0  0\n",
      "1414  0  1  0  0  0  0\n",
      "1415  0  1  0  0  0  0\n",
      "1416  0  1  0  0  0  0\n",
      "1417  0  1  0  0  0  0\n",
      "1418  0  1  0  0  0  0\n",
      "1419  0  1  0  0  0  0\n",
      "1420  0  1  0  0  0  0\n",
      "1421  0  1  0  0  0  0\n",
      "1422  0  1  0  0  0  0\n",
      "1423  0  1  0  0  0  0\n",
      "1424  0  1  0  0  0  0\n",
      "1425  0  1  0  0  0  0\n",
      "1426  0  1  0  0  0  0\n",
      "1427  0  1  0  0  0  0\n",
      "1428  0  1  0  0  0  0\n",
      "1429  0  1  0  0  0  0\n",
      "...  .. .. .. .. .. ..\n",
      "1470  0  1  0  0  0  0\n",
      "1471  0  1  0  0  0  0\n",
      "1472  0  1  0  0  0  0\n",
      "1473  0  1  0  0  0  0\n",
      "1474  0  1  0  0  0  0\n",
      "1475  0  1  0  0  0  0\n",
      "1476  0  1  0  0  0  0\n",
      "1477  0  1  0  0  0  0\n",
      "1478  0  1  0  0  0  0\n",
      "1479  0  1  0  0  0  0\n",
      "1480  0  1  0  0  0  0\n",
      "1481  0  1  0  0  0  0\n",
      "1482  0  1  0  0  0  0\n",
      "1483  0  1  0  0  0  0\n",
      "1484  0  1  0  0  0  0\n",
      "1485  0  1  0  0  0  0\n",
      "1486  0  1  0  0  0  0\n",
      "1487  0  1  0  0  0  0\n",
      "1488  0  1  0  0  0  0\n",
      "1489  0  1  0  0  0  0\n",
      "1490  0  1  0  0  0  0\n",
      "1491  0  1  0  0  0  0\n",
      "1492  0  1  0  0  0  0\n",
      "1493  0  1  0  0  0  0\n",
      "1494  0  1  0  0  0  0\n",
      "1495  0  1  0  0  0  0\n",
      "1496  0  1  0  0  0  0\n",
      "1497  0  1  0  0  0  0\n",
      "1498  0  1  0  0  0  0\n",
      "1499  0  1  0  0  0  0\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(BATCHES_LABELS[14]) # Confirm one hot labels are batched "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell contains a function that runs the tensorflow session, it is called with the x placeholders.\n",
    "The session is ran by first initializing all the tensorflow variables, then iterated through\n",
    "the number of epochs and feed the image data and labels using feed_dict.\n",
    "The loss/cost and accuracy is evaluated and printed to the console.\n",
    "\n",
    "'''\n",
    "\n",
    "def train_network(x):\n",
    "    pred = convolutional_network(x)\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = pred))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer()) # Initialize all the variables\n",
    "        saver = tf.train.Saver()\n",
    "    \n",
    "        time_full_start = time.clock()\n",
    "        print(\"RUNNING SESSION...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            train_batch_x = []\n",
    "            train_batch_y = []\n",
    "            epoch_loss = 0\n",
    "            time_epoch_start = time.clock()\n",
    "            for i in range(0, 84):\n",
    "                train_batch_x = BATCHES_IMAGES[i]\n",
    "#                 train_batch_y = BATCHES_LABELS[i]    \n",
    "#                 train_batch_y = np.array(train_batch_y)\n",
    "                op , loss_value = sess.run([train_op, loss], feed_dict={x: train_batch_x, y: train_batch_y})\n",
    "                epoch_loss += loss_value\n",
    "                print('batch ', i)\n",
    "            print('Epoch : ', epoch+1, ' of ', num_epochs, ' - Loss for epoch: ', epoch_loss)\n",
    "            \n",
    "            time_epoch_end = time.clock()\n",
    "            print('Time elapse: ', time_epoch_end - time_epoch_start)\n",
    "\n",
    "        time_full_end = time.clock()\n",
    "        print('Full time elapse:', time_full_end - time_full_start)\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', acc)\n",
    "\n",
    "        save_path = saver.save(sess, MODEL_PATH)\n",
    "        print(\"Model saved in file: \" , save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SESSION...\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must have the same first dimension, got logits shape [200,6] and labels shape [0]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](add_33, _arg_Y_placeholder_1_0_1)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-68565fbf7991>\", line 1, in <module>\n    train_network(x)\n  File \"<ipython-input-33-4ef3172cd9f1>\", line 11, in train_network\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = pred))\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1693, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2491, in _sparse_softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [200,6] and labels shape [0]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](add_33, _arg_Y_placeholder_1_0_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [200,6] and labels shape [0]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](add_33, _arg_Y_placeholder_1_0_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-68565fbf7991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-4ef3172cd9f1>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#                 train_batch_y = BATCHES_LABELS[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#                 train_batch_y = np.array(train_batch_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mop\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_batch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_batch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [200,6] and labels shape [0]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](add_33, _arg_Y_placeholder_1_0_1)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-68565fbf7991>\", line 1, in <module>\n    train_network(x)\n  File \"<ipython-input-33-4ef3172cd9f1>\", line 11, in train_network\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = pred))\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1693, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2491, in _sparse_softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [200,6] and labels shape [0]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](add_33, _arg_Y_placeholder_1_0_1)]]\n"
     ]
    }
   ],
   "source": [
    "train_network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
