{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is a testing script for the trained model\n",
    "\n",
    "@Author : Aaron Ward \n",
    "'''\n",
    "import tensorflow as tf\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import skimage\n",
    "from skimage import data, io, filters\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  #Suppress AVX Warnings\n",
    "\n",
    "TESTING_DIR = os.getcwd() +'/data/testing'\n",
    "TRAINED_MODEL = os.getcwd() + '/output/trained_model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################### DATA PREPROCESSING - Labeling ################################################\n",
    "'''\n",
    "This function traverses throwe ach directory of training images\n",
    "Two lists are made:\n",
    "    - The RGB image values are added to the images list\n",
    "    - For every photo in say the 'angry' directory of images, a \n",
    "      corresponding label is added to the label list\n",
    "\n",
    "'''\n",
    "def load_data(TESTING_DIR):\n",
    "    images = []\n",
    "    labels = []\n",
    "    directories = [d for d in os.listdir(TESTING_DIR) \n",
    "                if os.path.isdir(os.path.join(TESTING_DIR, d))]\n",
    "\n",
    "    # Traverse through each directory and make a list\n",
    "    # of files names if they end in the PNG format\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(TESTING_DIR, d)\n",
    "        file_names = [os.path.join(label_directory, f) \n",
    "                        for f in os.listdir(label_directory) \n",
    "                          if f.endswith(\".png\")]\n",
    "        #Traverse through each file, add the image data\n",
    "        # and label to the 2 lists\n",
    "        for f in file_names:\n",
    "            images.append(skimage.data.imread(f))\n",
    "            labels.append(int(d))\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_data(TESTING_DIR)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down scaling images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaron\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "####################################### DATA PREPROCESSING - Imaging #######################################\n",
    "'''\n",
    "This cell is for image downsampling and transformation\n",
    "This is on the fly to resize the images to a 50x50 size\n",
    "'''\n",
    "from skimage import transform, exposure\n",
    "# from skimage.color import rgb2gray\n",
    "\n",
    "print('Down scaling images...')\n",
    "images = [transform.resize(image, (50, 50)) for image in images]\n",
    "\n",
    "# print('equalizing exposure...')\n",
    "# images = [exposure.equalize_adapthist(image, clip_limit=0.0001)for image in images50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################### VARIABLE INITIATATION #################################################\n",
    "'''\n",
    "This cell is for initializing variables for the tensorflow session and \n",
    "placeholders for holding the data.\n",
    "\n",
    "'''\n",
    "# Define initial variables\n",
    "batch_size = 100\n",
    "num_class = 6\n",
    "\n",
    "# Initialize placeholders \n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 50, 50])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ######################################## HELPER FUNCTIONS #################################################\n",
    "\n",
    "'''\n",
    "This cell just contains helper functions for defining convolution\n",
    "and maxpooling layers\n",
    "\n",
    "'''\n",
    "# Extract features\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') #move one pixel at s time\n",
    "\n",
    "#\n",
    "def maxpool2d(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #pool 2 pixels at a time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################## NETWORK DEFINITION ################################################\n",
    "'''\n",
    "This cell contains a function that is used define the weights and biases of each layer in the\n",
    "network. It is called by the train_network function. It also lays out the\n",
    "structure of the network that goes as follows:\n",
    "conv1 -> maxpooling -> conv2 -> maxpooling - > conv3 -> fully connected layer (with dropout) -> output layer\n",
    "\n",
    "'''\n",
    "\n",
    "# Define the weights and biases as dictionaries and\n",
    "# define structure of the network\n",
    "def convolutional_network(x):\n",
    "    weights = {\n",
    "        'weights_conv1' : tf.Variable(tf.random_normal([5,5,1,64])),\n",
    "        'weights_conv2' : tf.Variable(tf.random_normal([5,5,64,128])),\n",
    "        'weights_conv3' : tf.Variable(tf.random_normal([5,5,128,256])),\n",
    "        'weights_fully_con' : tf.Variable(tf.random_normal([7*7*256,4096])),\n",
    "        'weights_out' : tf.Variable(tf.random_normal([4096, num_class]))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'bias_conv1' : tf.Variable(tf.random_normal([64])),\n",
    "        'bias_conv2' : tf.Variable(tf.random_normal([128])),\n",
    "        'bias_conv3' : tf.Variable(tf.random_normal([256])),\n",
    "        'bias_fully_con' : tf.Variable(tf.random_normal([4096])),\n",
    "        'bias_out' : tf.Variable(tf.random_normal([num_class]))\n",
    "    }\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, 50, 50, 1])\n",
    "\n",
    "    # 3 comvolutional and 3 max pooling layers\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['weights_conv1']) + biases['bias_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['weights_conv2']) + biases['bias_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    conv3 = tf.nn.relu(conv2d(conv2, weights['weights_conv3']) + biases['bias_conv3'])\n",
    "    conv3 = maxpool2d(conv3)\n",
    "\n",
    "    # The fully connected layer\n",
    "    fully_con = tf.reshape(conv3, [-1, 7*7*256])\n",
    "    fully_con = tf.nn.relu(tf.matmul(fully_con, weights['weights_fully_con']) + biases['bias_fully_con'])\n",
    "    # fc = tf.nn.dropout(fully_con, keep_rate) # Apply dropout\n",
    "\n",
    "    output = tf.matmul(fully_con, weights['weights_out']) + biases['bias_out']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100  images\n",
      "2100  labels\n",
      "batch size  100\n",
      "Number of batches  21\n"
     ]
    }
   ],
   "source": [
    "######################################## BATCHING ###################################################\n",
    "'''\n",
    "This cell is for segmenting the training data in to batches to relieve the GPU of being overloaded\n",
    "with data.\n",
    "\n",
    "'''\n",
    "# 8400 images and 8400 labels\n",
    "num_images = len(images)\n",
    "num_labels = len(labels)\n",
    "\n",
    "# ## KEEP THESE FOR DEBUGGING\n",
    "print(num_images, ' images')\n",
    "print(num_labels, ' labels')\n",
    "print('batch size ', batch_size)\n",
    "print('Number of batches ', int(num_images/batch_size))\n",
    "\n",
    "batch_start= 0\n",
    "batch_end = 100\n",
    "\n",
    "BATCHES_IMAGES = []\n",
    "BATCHES_LABELS = []\n",
    "\n",
    "# batch images into 84 batchs of size 100\n",
    "for i in range(int(num_images/batch_size)):\n",
    "    temp_batch = images[batch_start:batch_end]\n",
    "    BATCHES_IMAGES.append(temp_batch)\n",
    "    batch_start = batch_start + 100\n",
    "    batch_end = batch_end + 100\n",
    "\n",
    "batch_start = 0\n",
    "batch_end = 100\n",
    "# batch the 8400 Label into 84 batchs of 100\n",
    "for i in range(int(num_labels/batch_size)):\n",
    "    temp_batch = labels[batch_start:batch_end]\n",
    "    BATCHES_LABELS.append(temp_batch)\n",
    "    batch_start = batch_start + 100\n",
    "    batch_end = batch_end + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_network(x):\n",
    "    pred = convolutional_network(x)\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = pred))\n",
    "    # train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "#     loss = tf.reduce_sum(tf.square(pred - tf.cast(y, tf.float32)))\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print('Start Session ...')\n",
    "        sess.run(tf.global_variables_initializer()) # Initialize all the variables\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        \n",
    "        average_err =0\n",
    "        test_batch_x = []\n",
    "        test_batch_t = []\n",
    "        for i in range(0, 21):\n",
    "            test_batch_x = BATCHES_IMAGES[i]\n",
    "            test_batch_y = BATCHES_LABELS[i]\n",
    "            pr, loss_value = sess.run([pred, loss], feed_dict={x: test_batch_x, y: test_batch_y})\n",
    "            \n",
    "            for i in range(len(pr)):\n",
    "                err = abs(pr[i] - y[i])\n",
    "                print('\\t - Error: ', err, '\\t - Loss: ', loss_value )\n",
    "                average_err += err\n",
    "            average_err = average_err/len(pr)\n",
    "            print('Average Error: ', average_err)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "#         acc = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Session ...\n",
      "\t - Error:  Tensor(\"Abs_102:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_103:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_104:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_105:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_106:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_107:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_108:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_109:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_110:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_111:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_112:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_113:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_114:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_115:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_116:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_117:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_118:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_119:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_120:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_121:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_122:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_123:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_124:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_125:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_126:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_127:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_128:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_129:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_130:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_131:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_132:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_133:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_134:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_135:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_136:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_137:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_138:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_139:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_140:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_141:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_142:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_143:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_144:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_145:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_146:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_147:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_148:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_149:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_150:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_151:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_152:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_153:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_154:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_155:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_156:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_157:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_158:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_159:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_160:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_161:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_162:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_163:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_164:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_165:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_166:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_167:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_168:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_169:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_170:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_171:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_172:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_173:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_174:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_175:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_176:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_177:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_178:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_179:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_180:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_181:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_182:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_183:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_184:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_185:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_186:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_187:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_188:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_189:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_190:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_191:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_192:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_193:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_194:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_195:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_196:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_197:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_198:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_199:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_200:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "\t - Error:  Tensor(\"Abs_201:0\", shape=(6,), dtype=int32) \t - Loss:  1.39577e+07\n",
      "Average Error:  Tensor(\"truediv_1:0\", shape=(6,), dtype=float64)\n",
      "\t - Error:  Tensor(\"Abs_202:0\", shape=(6,), dtype=int32) \t - Loss:  1.38759e+07\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype float64 for Tensor with dtype int32: 'Tensor(\"Abs_202:0\", shape=(6,), dtype=int32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-662ba0ec92bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meval_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-68f31f16e3b5>\u001b[0m in \u001b[0;36meval_network\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t - Error: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\t - Loss: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0maverage_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0maverage_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_err\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Average Error: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\aaron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m           \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m           \u001b[1;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\aaron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\aaron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m           \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\aaron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[1;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    547\u001b[0m     raise ValueError(\n\u001b[0;32m    548\u001b[0m         \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         % (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[0;32m    550\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype float64 for Tensor with dtype int32: 'Tensor(\"Abs_202:0\", shape=(6,), dtype=int32)'"
     ]
    }
   ],
   "source": [
    "eval_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single(x):\n",
    "    \n",
    "    \n",
    "    \n",
    "    classification = sess.run(tf.argmax(y, 1), feed_dict={x:})\n",
    "    \n",
    "    print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
