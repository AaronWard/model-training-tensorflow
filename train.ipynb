{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the model that will be used to train the deep convolutional neaural network.\n",
    "\n",
    "@Author : Aaron Ward \n",
    "'''\n",
    "import tensorflow as tf\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import skimage\n",
    "from skimage import data, io, filters\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = os.getcwd()\n",
    "TRAINING_DIR = os.getcwd() + '/data/training'\n",
    "MODEL_PATH = os.getcwd() + '/output/trained_model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################### DATA PREPROCESSING - Labeling ################################################\n",
    "'''\n",
    "This function traverses throwe ach directory of training images\n",
    "Two lists are made:\n",
    "    - The RGB image values are added to the images list\n",
    "    - For every photo in say the 'angry' directory of images, a \n",
    "      corresponding label is added to the label list\n",
    "\n",
    "'''\n",
    "def load_data(TRAINING_DIR):\n",
    "    images = []\n",
    "    labels = []\n",
    "    directories = [d for d in os.listdir(TRAINING_DIR) \n",
    "                if os.path.isdir(os.path.join(TRAINING_DIR, d))]\n",
    "\n",
    "    # Traverse through each directory and make a list\n",
    "    # of files names if they end in the PNG format\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(TRAINING_DIR, d)\n",
    "        file_names = [os.path.join(label_directory, f) \n",
    "                        for f in os.listdir(label_directory) \n",
    "                          if f.endswith(\".png\")]\n",
    "        #Traverse through each file, add the image data\n",
    "        # and label to the 2 lists\n",
    "        for f in file_names:\n",
    "            images.append(skimage.data.imread(f))\n",
    "            labels.append(int(d))\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_data(TRAINING_DIR)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down scaling images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaron\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "####################################### DATA PREPROCESSING - Imaging #######################################\n",
    "'''\n",
    "This cell is for image downsampling and transformation\n",
    "This is on the fly to resize the images to a 50x50 size\n",
    "'''\n",
    "\n",
    "from skimage import transform, exposure\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "print('Down scaling images...')\n",
    "images = [transform.resize(image, (50, 50)) for image in images]\n",
    "\n",
    "# print('equalizing exposure...')\n",
    "# images = [exposure.equalize_adapthist(image, clip_limit=0.0001)for image in images50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### VARIABLE INITIATATION #################################################\n",
    "'''\n",
    "This cell is for initializing variables for the tensorflow session and \n",
    "placeholders for holding the data.\n",
    "\n",
    "'''\n",
    "\n",
    "# Define initial variables\n",
    "batch_size = 100\n",
    "num_class = 6\n",
    "num_epochs = 25\n",
    "\n",
    "# Initialize placeholders \n",
    "# x = tf.placeholder('float', [5582, 50, 50])\n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 50, 50])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
    "\n",
    "#define variables for dropout\n",
    "keep_rate = .8\n",
    "keep_prop = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################### HELPER FUNCTIONS #################################################\n",
    "\n",
    "'''\n",
    "This cell just contains helper functions for defining convolution\n",
    "and maxpooling layers\n",
    "\n",
    "'''\n",
    "\n",
    "# Extract features\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') #move one pixel at s time\n",
    "\n",
    "#\n",
    "def maxpool2d(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #pool 2 pixels at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################## NETWORK DEFINITION ################################################\n",
    "'''\n",
    "This cell contains a function that is used define the weights and biases of each layer in the\n",
    "network. It is called by the train_network function. It also lays out the\n",
    "structure of the network that goes as follows:\n",
    "conv1 -> maxpooling -> conv2 -> maxpooling - > conv3 -> fully connected layer (with dropout) -> output layer\n",
    "\n",
    "'''\n",
    "\n",
    "# Define the weights and biases as dictionaries and\n",
    "# define structure of the network\n",
    "def convolutional_network(x):\n",
    "    weights = {\n",
    "        'weights_conv1' : tf.Variable(tf.random_normal([5,5,1,64])),\n",
    "        'weights_conv2' : tf.Variable(tf.random_normal([5,5,64,128])),\n",
    "        'weights_conv3' : tf.Variable(tf.random_normal([5,5,128,256])),\n",
    "        'weights_fully_con' : tf.Variable(tf.random_normal([7*7*256,4096])),\n",
    "        'weights_out' : tf.Variable(tf.random_normal([4096, num_class]))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'bias_conv1' : tf.Variable(tf.random_normal([64])),\n",
    "        'bias_conv2' : tf.Variable(tf.random_normal([128])),\n",
    "        'bias_conv3' : tf.Variable(tf.random_normal([256])),\n",
    "        'bias_fully_con' : tf.Variable(tf.random_normal([4096])),\n",
    "        'bias_out' : tf.Variable(tf.random_normal([num_class]))\n",
    "    }\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, 50, 50, 1])\n",
    "\n",
    "    # 3 comvolutional and 3 max pooling layers\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['weights_conv1']) + biases['bias_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['weights_conv2']) + biases['bias_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    conv3 = tf.nn.relu(conv2d(conv2, weights['weights_conv3']) + biases['bias_conv3'])\n",
    "    conv3 = maxpool2d(conv3)\n",
    "\n",
    "    # The fully connected layer\n",
    "    fully_con = tf.reshape(conv3, [-1, 7*7*256])\n",
    "    fully_con = tf.nn.relu(tf.matmul(fully_con, weights['weights_fully_con']) + biases['bias_fully_con'])\n",
    "    fc = tf.nn.dropout(fully_con, keep_rate) # Apply dropout\n",
    "\n",
    "    output = tf.matmul(fully_con, weights['weights_out']) + biases['bias_out']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################## TENSORFLOW SESSION ###################################################\n",
    "'''\n",
    "This cell contains a function that runs the tensorflow session, it is called with the x placeholders.\n",
    "The session is ran by first initializing all the tensorflow variables, then iterated through\n",
    "the number of epochs and feed the image data and labels using feed_dict.\n",
    "The loss/cost and accuracy is evaluated and printed to the console.\n",
    "\n",
    "'''\n",
    "\n",
    "def train_network(x):\n",
    "    pred = convolutional_network(x)\n",
    "    # cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels= y))\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = pred))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer()) # Initialize all the variables\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        print(\"RUNNING SESSION...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            for _ in range(1):\n",
    "                _, loss_value = sess.run([train_op, loss], feed_dict={x: images, y: labels})\n",
    "                print(\"feed\")\n",
    "            print('Epoch : ', epoch+1, ' of ', num_epochs, ' - Loss: ', loss_value)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', acc)\n",
    "\n",
    "        save_path = saver.save(sess, MODEL_PATH)\n",
    "        print(\"Model saved in file: \" , save_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SESSION...\n"
     ]
    }
   ],
   "source": [
    "train_network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
